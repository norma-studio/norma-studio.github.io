
<!DOCTYPE html>
<html lang="ru"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
<title>Введение в обнаружение лиц на Android... | envatomarket.ru | norma-studio.github.io</title>
<meta name="twitter:card" content="summary_large_image">
<meta property="og:title" content="Введение в обнаружение лиц на Android... | envatomarket.ru | norma-studio.github.io">
<meta name="twitter:title" content="Введение в обнаружение лиц на Android... | envatomarket.ru | norma-studio.github.io">
<meta name="aiturec:title" content="Введение в обнаружение лиц на Android... | envatomarket.ru | norma-studio.github.io">
<meta name="description" content="Представленная с библиотеками Vision в Play Services 8.1, Face Detection позволяет вам как разработчику анализировать видео или изображение, чтобы найти человеческие лица.  Когда у вас есть список лиц, обнаруженных на изображении, вы можете собирать информацию о каждом лице, таком как ориентация, вероятность улыбки, открывать или закрывать глаза у ...">
<meta property="og:description" content="Представленная с библиотеками Vision в Play Services 8.1, Face Detection позволяет вам как разработчику анализировать видео или изображение, чтобы найти человеческие лица.  Когда у вас есть список лиц, обнаруженных на изображении, вы можете собирать информацию о каждом лице, таком как ориентация, вероятность улыбки, открывать или закрывать глаза у ...">
<meta name="twitter:description" content="Представленная с библиотеками Vision в Play Services 8.1, Face Detection позволяет вам как разработчику анализировать видео или изображение, чтобы найти человеческие лица.  Когда у вас есть список лиц, обнаруженных на изображении, вы можете собирать информацию о каждом лице, таком как ориентация, вероятность улыбки, открывать или закрывать глаза у ...">
<meta property="aiturec:description" content="Представленная с библиотеками Vision в Play Services 8.1, Face Detection позволяет вам как разработчику анализировать видео или изображение, чтобы найти человеческие лица.  Когда у вас есть список лиц, обнаруженных на изображении, вы можете собирать информацию о каждом лице, таком как ориентация, вероятность улыбки, открывать или закрывать глаза у ...">
<meta property="og:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=600/uploads/users/798/posts/25212/image/unicorn.png">
<meta property="aiturec:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=600/uploads/users/798/posts/25212/image/unicorn.png">
<meta name="twitter:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=600/uploads/users/798/posts/25212/image/unicorn.png">
<meta property="vk:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=600/uploads/users/798/posts/25212/image/unicorn.png">
<meta property="og:type" content="article">
<link image_src="image" href="https://cms-assets.tutsplus.com/cdn-cgi/image/width=600/uploads/users/798/posts/25212/image/unicorn.png">
<meta property="og:locale" content="ru_RU"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name="robots" content="all">
<meta name="author" content="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android.html">
<meta name="copyright" lang="ru" content="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android.html">
<link rel="canonical" href="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android.html">
<meta property="og:url" content="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android.html">
<meta name="twitter:site" content="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android.html">
<meta name="twitter:creator" content="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android.html">

<meta name="apple-mobile-web-app-status-bar-style" content="#303b44"><meta name="msapplication-TileColor" content="#629FBC">
<link rel="shortcut icon" type="image/ico" sizes="64x64" href="https://norma-studio.github.io//norma-logo-64.png">
<link rel="shortcut icon" href="https://norma-studio.github.io//favicon.ico" type="image/x-icon">
<style>body{opacity: 0;}</style>
<meta name="yandex-verification" content="da91da9b0b6d5dba"><meta name="google-site-verification" content="_BCz7bv6IKv32EI5NSdb9dPwP4PnhlsToVoSOpbZlZI"></head><body>
<div id="app"><div class="tm-layout__wrapper"><div></div>
<header id="extop" class="tm-header"><div class="tm-page-width"><div class="tm-header__container">

<span class="tm-header__logo-wrap"><a aria-label="norma-studio.github.io" href="https://norma-studio.github.io/" class="tm-header__logo tm-header__logo_ru" title="Подборка эксклюзивных материалов о создании и продвижении сайтов, дизайне сайтов и интернет-маркетинге. Как создать и продвигать сайт, как выбрать дизайн сайта и интернет-стратегию, как защитить свои права в интернете, как продать контент для сайтов? Все ответы в блоге norma-studio.github.io">norma-studio.github.io</a></span><div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title><svg id="arrow-down" viewBox="0 0 24 24"><path d="m6.47 9.47c.293-.293.768-.293 1.061 0l4.47 4.47 4.47-4.47c.293-.293.768-.293 1.061 0s.293.768 0 1.061l-5 5c-.293.293-.768.293-1.061 0l-5-5c-.293-.293-.293-.768 0-1.061z"></path></svg></svg></button></div></div><a aria-label="Написать нам" href="https://wa.me/79603570433?text=https://norma-studio.github.io/_Добрый_день" class="tm-header__become-author-btn" title="Подборка эксклюзивных материалов о создании и продвижении сайтов, дизайне сайтов и интернет-маркетинге. Как создать и продвигать сайт, как выбрать дизайн сайта и интернет-стратегию, как защитить свои права в интернете, как продать контент для сайтов? Все ответы в блоге envatomarket.ru.">Написать нам</a><div class="tm-feature tm-header__feature tm-feature_variant-inline"></div></div></div></header>

<div class="tm-layout">
<main class="tm-layout__container"><div class="tm-page"><div class="tm-page-width"><div class="tm-page__wrapper">
<div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down">
<div class="tm-page-article__body data-container" style="background-color: #f0f0f0;" id="data-container">


<article class="tm-page-article__content tm-page-article__content_inner" style="background-color: #fff;">
<!-- article-header -->
<div class="tm-page-article__head-wrapper"><div class="tm-article-snippet tm-page-article__snippet">

<div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a aria-label="author-image" href="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android.html" title="Введение в обнаружение лиц на Android... | envatomarket.ru | norma-studio.github.io" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="Введение в обнаружение лиц на Android... | envatomarket.ru | norma-studio.github.io" title="Введение в обнаружение лиц на Android... | envatomarket.ru | norma-studio.github.io" height="24" src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-src="https://envatomarket.ru/i3/64533jghfdd.webp" width="24" class="tm-entity-image__pic lazy07"></div></a><span class="tm-user-info__user">
<a href="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android.html" class="tm-user-info__username" title="
Д. Слесарев" aria-label="
Д. Слесарев">
Д. Слесарев</a>
</span></span><span class="tm-article-snippet__datetime-published"><time datetime="2023-12-09T15:24:38.000Z" title="22023-12-09, 19:24"> 09.12.2023</time></span></div></div>
<h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1" itemprop="name"><span><span>Введение в обнаружение лиц на Android...</span></span></h1>
<div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a aria-label="Code" href="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android" class="tm-article-snippet__hubs-item-link"><span>Code</span></a></span><span class="tm-article-snippet__hubs-item"><a aria-label="Android SDK" href="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android" class="tm-article-snippet__hubs-item-link"><span>Android SDK</span></a></span><br></div></div>

<div itemscope itemtype="https://schema.org/Article" style="display:none;">
    <link itemprop="mainEntityOfPage" href="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android.html" />
    <link itemprop="image" href="https://cms-assets.tutsplus.com/cdn-cgi/image/width=600/uploads/users/798/posts/25212/image/unicorn.png">
    <meta itemprop="headline name" content="Введение в обнаружение лиц на Android... | envatomarket.ru | norma-studio.github.io">
    <meta itemprop="description" content="Представленная с библиотеками Vision в Play Services 8.1, Face Detection позволяет вам как разработчику анализировать видео или изображение, чтобы найти человеческие лица.  Когда у вас есть список лиц, обнаруженных на изображении, вы можете собирать информацию о каждом лице, таком как ориентация, вероятность улыбки, открывать или закрывать глаза у ...">
    <meta itemprop="author" content="norma-studio.github.io">
    <meta itemprop="datePublished" datetime="2023-12-09T15:24:38.000Z" content="09.12.2023">
    <meta itemprop="dateModified" datetime="2023-12-09T15:24:38.000Z" content="09.12.2023">
    <div itemprop="publisher" itemscope itemtype="https://schema.org/Organization">
        <div itemprop="logo" itemscope itemtype="https://schema.org/ImageObject">
            <img class="lazy07" itemprop="url image" src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-src="https://envatomarket.ru/apple-touch-icon-120.ico" alt="Шаблоны сайтов | Лендинги" title="Шаблоны сайтов | Лендинги" style="display:none;"/>
        </div>
        <meta itemprop="name" content="https://norma-studio.github.io/">
        <meta itemprop="telephone" content="">
        <meta itemprop="address" content="Россия">
    </div>
    <p>Интро</p>
    <span itemprop="articleBody">Представленная с библиотеками Vision в Play Services 8.1, Face Detection позволяет вам как разработчику анализировать видео или изображение, чтобы найти человеческие лица.  Когда у вас есть список лиц, обнаруженных на изображении, вы можете собирать информацию о каждом лице, таком как ориентация, вероятность улыбки, открывать или закрывать глаза у ...</span>
</div>


<!-- article-body -->

<div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-2">



<p>Представленная с библиотеками Vision в Play Services 8.1, Face Detection позволяет вам как разработчику анализировать видео или изображение, чтобы найти человеческие лица.  Когда у вас есть список лиц, обнаруженных на изображении, вы можете собирать информацию о каждом лице, таком как ориентация, вероятность улыбки, открывать или закрывать глаза у кого-то, а также конкретные ориентиры на их лице.</p><p>Эта информация может быть полезна для нескольких приложений, таких как приложение для камеры, которое автоматически делает снимок, когда все в рамке улыбаются с открытыми глазами или для увеличения изображений с глупыми эффектами, такими как рожки единорога.  Важно отметить, что распознавание лиц <strong>не</strong> является распознаванием лица.  Хотя информация может быть собрана о лицах, эта информация не используется библиотекой Vision для определения того, являются ли два лица одним и тем же лицом.</p><p>В этом руководстве будет использоваться неподвижное изображение для запуска API обнаружения лиц и сбора информации о людях на фотографии, а также иллюстрации этой информации с наложенной графикой.  Весь код этого руководства можно найти на <span>GitHub</span>.<br></p><figure><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=600/uploads/users/798/posts/25212/image/unicorn.png" alt="Введение в обнаружение лиц на Android..." title="Введение в обнаружение лиц на Android..." width="50" height="50"></figure><h2> <span class="sectionnum">1.</span> Настройка проекта</h2><p>Чтобы добавить библиотеку Vision в свой проект, вам необходимо импортировать Play Services 8.1 или более в ваш проект.  В этом учебнике импортируется только библиотека Play Services Vision.  Откройте файл <strong>build.gradle</strong> вашего проекта и добавьте следующую строку компиляции в узел <code class="inline">dependecies</code>.</p><pre class="brush: groovy noskimlinks noskimwords">compile "com.google.android.gms:play-services-vision:8.1.0"</pre><p>После того, как вы включили Play Services в свой проект, вы можете закрыть файл <strong>build.gradle</strong> вашего проекта и открыть <strong>AndroidManifest.xml</strong>.  Вам нужно добавить элемент <code class="inline">meta-data</code>, определяющий зависимость лица в узле <code class="inline">application</code> вашего манифеста.  Это позволяет библиотеке Vision знать, что вы планируете обнаруживать лица в своем приложении.</p><pre class="brush: xml noskimlinks noskimwords">&lt;meta-data android:name="com.google.android.gms.vision.DEPENDENCIES" android:value="face"/&gt;</pre><p>Когда вы закончите настройку <strong>AndroidManifest.xml</strong>, вы можете продолжить и закрыть его.  Затем вам нужно создать новый класс с именем <strong>FaceOverlayView.java</strong>.  Этот класс расширяет <code class="inline">View</code> и содержит логику обнаружения лиц в проекте, отображая растровое изображение, которое было проанализировано и нарисовано поверх изображения, чтобы проиллюстрировать точки.</p><p>Начнем с добавления переменных-членов в верхней части класса и определения конструкторов.  Объект <code class="inline">Bitmap</code> будет использоваться для хранения растрового изображения, которое будет проанализировано, и объекты <code class="inline">SparseArray</code> of <code class="inline">Face</code> будут хранить каждое лицо, найденное в растровом изображении.</p><pre class="brush: java noskimlinks noskimwords">public class FaceOverlayView extends View {    private Bitmap mBitmap;    private SparseArray&lt;Face&gt; mFaces;    public FaceOverlayView(Context context) {        this(context, null);    }    public FaceOverlayView(Context context, AttributeSet attrs) {        this(context, attrs, 0);    }    public FaceOverlayView(Context context, AttributeSet attrs, int defStyleAttr) {        super(context, attrs, defStyleAttr);    }}</pre><p>Затем добавьте новый метод внутри <code class="inline">FaceOverlayView</code>, называемый <code class="inline">setBitmap (Bitmap bitmap)</code>.  На данный момент это просто сохранит битмап, переданный ему, однако позже вы будете использовать этот метод для анализа изображения.</p><pre class="brush: java noskimlinks noskimwords">public void setBitmap( Bitmap bitmap ) {    mBitmap = bitmap;}</pre><p>Затем вам нужно растровое изображение.  Я включил один в пример проекта <span>GitHub</span>, но вы можете использовать любое изображение, которое вы хотели бы, чтобы играть с Face Detection и посмотреть, что работает, а что нет.  Когда вы выбрали изображение, поместите его в каталог <strong>res/raw</strong>.  В этом учебнике предполагается, что изображение называется <strong>face.jpg</strong>.</p><p>После того, как вы поместили свое изображение в каталог <strong>res/raw</strong>, откройте <strong>res/layout/activity_main.xml</strong>.  Этот макет содержит ссылку на <code class="inline">FaceOverlayView</code>, чтобы он отображался в <code class="inline">MainActivity</code>.</p><pre class="brush: xml noskimlinks noskimwords">&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;com.tutsplus.facedetection.FaceOverlayView    xmlns:android="https://schemas.android.com/apk/res/android"    android:id="@+id/face_overlay"    android:layout_width="match_parent"    android:layout_height="match_parent" /&gt;</pre><p>С установленным макетом откройте <code class="inline">MainActivity</code> и настройте <code class="inline">FaceOverlayView</code> из <code class="inline">onCreate()</code>.  Вы делаете это, получая ссылку на представление, просматривая файл изображения <strong>face.jpg</strong> из исходного каталога в качестве входного потока и преобразуя его в растровое изображение.  После того, как у вас есть растровое изображение, вы можете вызвать <code class="inline">setBitmap</code> на <code class="inline">FaceOverlayView</code>, чтобы передать изображение в свое пользовательское представление.</p><pre class="brush: java noskimlinks noskimwords">public class MainActivity extends AppCompatActivity {    private FaceOverlayView mFaceOverlayView;    @Override    protected void onCreate(Bundle savedInstanceState) {        super.onCreate(savedInstanceState);        setContentView(R.layout.activity_main);        mFaceOverlayView = (FaceOverlayView) findViewById( R.id.face_overlay );        InputStream stream = getResources().openRawResource( R.raw.face );        Bitmap bitmap = BitmapFactory.decodeStream(stream);        mFaceOverlayView.setBitmap(bitmap);    }}</pre><h2> <span class="sectionnum">2. </span>Обнаружение лиц</h2><p>Теперь, когда ваш проект настроен, пришло время начать распознавать лица. Android. В <code class="inline">setBitmap (Bitmap bitmap)</code> вам необходимо создать <code class="inline">FaceDetector</code>.  Это можно сделать с помощью <code class="inline">FaceDetector.Builder</code>, позволяя вам определить несколько параметров, которые влияют на то, как будут распознаваться быстрые лица и какие другие данные создаст <code class="inline">FaceDetector</code>.</p><p>Параметры, которые вы выбираете, зависят от того, что вы пытаетесь сделать в своем приложении.  Если вы включите поиск ориентиров, то лица будут обнаружены медленнее.  Как и в большинстве случаев в программировании, все имеет свои компромиссы.  Чтобы узнать больше о вариантах, доступных для <code class="inline">FaceDetector.Builder</code>, вы можете найти официальную документацию на <span>веб-сайте разработчика</span> </p><pre class="brush: java noskimlinks noskimwords">FaceDetector detector = new FaceDetector.Builder( getContext() )        .setTrackingEnabled(false)        .setLandmarkType(FaceDetector.ALL_LANDMARKS)        .setMode(FaceDetector.FAST_MODE)        .build();</pre><p>Вам также необходимо проверить, работает ли <code class="inline">FaceDetector</code>.  Когда пользователь впервые использует обнаружение лиц на своем устройстве, Play Services необходимо выйти и получить набор небольших собственных библиотек для обработки запроса вашего приложения.  Хотя это почти всегда будет сделано до того, как ваше приложение завершит запуск, важно справиться с непредвиденными обстоятельствами, что это не удалось.</p><p>Если <code class="inline">FaceDetector</code> работает, вы можете преобразовать растровое изображение в объект <code class="inline">Frame</code> и передать его детектору для сбора данных о лицах на изображении.  Когда вы закончите, вам нужно будет отпустить детектор, чтобы предотвратить утечку памяти.  Когда вы закончите обнаружение лиц, вызовите <code class="inline">invalidate()</code>, чтобы вызвать перерисовку представления.</p><pre class="brush: java noskimlinks noskimwords">if (!detector.isOperational()) {    //Handle contingency} else {    Frame frame = new Frame.Builder().setBitmap(bitmap).build();    mFaces = detector.detect(frame);    detector.release();}invalidate();</pre><p>Теперь, когда вы обнаружили лица на своем изображении, пришло время их использовать.  В этом примере вы просто нарисуете зеленую рамку вокруг каждого лица.  Поскольку <code class="inline">invalidate() </code>вызывается после того, как лица были обнаружены, вы можете добавить всю необходимую логику в <code class="inline">onDraw (Canvas canvas)</code>.  Этот метод гарантирует, что битмап и грани установлены, затем нарисуйте растровое изображение на холсте, а затем нарисуйте квадрат вокруг каждой грани.</p><p>Так как разные устройства имеют разные размеры дисплея, вы также будете отслеживать масштабированный размер растрового изображения, чтобы все изображение было всегда видимым на устройстве, и все наложения рисуются соответствующим образом.</p><pre class="brush: java noskimlinks noskimwords">@Overrideprotected void onDraw(Canvas canvas) {    super.onDraw(canvas);    if ((mBitmap != null) &amp;&amp; (mFaces != null)) {        double scale = drawBitmap(canvas);        drawFaceBox(canvas, scale);    }}</pre><p>Метод <code class="inline">drawBitmap (Canvas canvas)</code> рисует ваше растровое изображение на холсте и соответствующим образом определяет его, а также возвращает множитель для правильного масштабирования ваших других измерений.</p><pre class="brush: java noskimlinks noskimwords">private double drawBitmap( Canvas canvas ) {    double viewWidth = canvas.getWidth();    double viewHeight = canvas.getHeight();    double imageWidth = mBitmap.getWidth();    double imageHeight = mBitmap.getHeight();    double scale = Math.min( viewWidth / imageWidth, viewHeight / imageHeight );    Rect destBounds = new Rect( 0, 0, (int) ( imageWidth * scale ), (int) ( imageHeight * scale ) );    canvas.drawBitmap( mBitmap, null, destBounds, null );    return scale;}</pre><p>Метод <code class="inline">drawFaceBox (Canvas canvas, double scale)</code> становится немного интереснее.  Каждое обнаруженное и сохраненное лицо имеет значение позиции выше и слева от каждого лица.  Этот метод займет это положение и нарисует из него зеленый прямоугольник, чтобы охватить каждую грань в зависимости от ее ширины и высоты.</p><p>Вам нужно определить свой объект <code class="inline">Paint</code>, а затем прокрутить каждое <code class="inline">Face</code> в вашем <code class="inline">SparseArray</code>, чтобы найти его положение, ширину и высоту и нарисовать прямоугольник на холсте, используя эту информацию.</p><pre class="brush: java noskimlinks noskimwords">private void drawFaceBox(Canvas canvas, double scale) {    //paint should be defined as a member variable rather than     //being created on each onDraw request, but left here for     //emphasis.    Paint paint = new Paint();    paint.setColor(Color.GREEN);    paint.setStyle(Paint.Style.STROKE);    paint.setStrokeWidth(5);    float left = 0;    float top = 0;    float right = 0;    float bottom = 0;    for( int i = 0; i &lt; mFaces.size(); i++ ) {        Face face = mFaces.valueAt(i);        left = (float) ( face.getPosition().x * scale );        top = (float) ( face.getPosition().y * scale );        right = (float) scale * ( face.getPosition().x + face.getWidth() );        bottom = (float) scale * ( face.getPosition().y + face.getHeight() );        canvas.drawRect( left, top, right, bottom, paint );    }}</pre><p>На этом этапе вы сможете запустить приложение и увидеть свое изображение с прямоугольниками вокруг каждого обнаруженного лица.  Важно отметить, что API распознавания лиц по-прежнему остается довольно новым на момент написания этой статьи, и он не может обнаружить каждого лица.  Вы можете играть с некоторыми настройками в объекте <code class="inline">FaceDetector.Builder</code>, чтобы надеяться собрать больше данных, хотя это не гарантировано.</p><figure><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=600/uploads/users/798/posts/25212/image/facebox.png" alt="Введение в обнаружение лиц на Android..." title="Введение в обнаружение лиц на Android..." width="50" height="50"></figure><h2> <span class="sectionnum">3.</span> Понимание ориентиров</h2><p>Ориентиры - это точки интереса на лице.  API Face Detection API не использует ориентиры для обнаружения лица, а скорее определяет лицо целиком, прежде чем искать ориентиры.  Вот почему открытие ориентиров - это необязательная настройка, которая может быть активирована через <code class="inline">FaceDetector.Builder</code>.</p><p>Вы можете использовать эти ориентиры в качестве дополнительного источника информации, например, где находятся глаза субъекта, чтобы вы могли реагировать соответствующим образом в своем приложении.  Есть <span>12 ориентиров</span>, которые можно найти:</p><ul><li>левый и правый глаз</li> <li>левое и правое ухо</li> <li>левый и правый ушные наконечники</li> <li>основание носа</li> <li>левая и правая щека</li> <li>левый и правый угол рта</li> <li>основание рта</li> </ul><p>Знаки, которые доступны, зависят от угла распознанного лица.  Например, у кого-то, стоящего перед боком, будет только один глаз, который означает, что другой глаз не будет обнаружен.  В следующей таблице показано, какие ориентиры должны обнаруживаться на основе угла Эйлера Y (направление влево или вправо) лица.<br></p><table><thead><tr><th>Euler Y </th> <th>Видимые ориентиры</th> </tr></thead><tbody><tr><td>&lt;-36 ° </td> <td>левый глаз, левый рот, левое ухо, основание носа, левая щека</td> </tr><tr><td>От -36 ° до -12 °  </td> <td>левый рот, основание носа, нижний рот, правый глаз, левый глаз, левая щека, левый ухо</td> </tr><tr><td>-12 ° до 12 ° </td> <td>правый глаз, левый глаз, основание носа, левая щека, правая щека, левый рот, правый рот, нижний рот</td> </tr><tr><td>12 ° до 36 ° </td> <td>правая рта, основание носа, нижний рот, левый глаз, правый глаз, правая щека, правый ушной наконечник</td> </tr><tr><td>&gt; 36°</td> <td>Правый правый глаз, правый рот, правое ухо, основание носа, правая щека<br></td> </tr></tbody></table><p>Ориентиры также невероятно просты в использовании в вашем приложении, поскольку вы уже включили их во время обнаружения лица.  Вам просто нужно вызвать <code class="inline">getLandmarks ()</code> на объекте <code class="inline">Face</code>, чтобы получить <code class="inline">List</code> из <code class="inline">Landmark</code>, с которыми вы можете работать.</p><p>В этом уроке вы нарисуете небольшой круг на каждом обнаруженном ориентире, вызвав новый метод, <code class="inline">drawFaceLandmarks(Canvas canvas, double scale)</code>, из <code class="inline">onDraw(canvas canvas)</code> вместо <code class="inline">drawFaceBox(Canvas canvas, double scale)</code>.  Этот метод занимает положение каждого ориентира, настраивает его для масштаба растрового изображения, а затем отображает знаковый круг индикатора.</p><pre class="brush: java noskimlinks noskimwords">private void drawFaceLandmarks( Canvas canvas, double scale ) {    Paint paint = new Paint();    paint.setColor( Color.GREEN );    paint.setStyle( Paint.Style.STROKE );    paint.setStrokeWidth( 5 );    for( int i = 0; i &lt; mFaces.size(); i++ ) {        Face face = mFaces.valueAt(i);        for ( Landmark landmark : face.getLandmarks() ) {            int cx = (int) ( landmark.getPosition().x * scale );            int cy = (int) ( landmark.getPosition().y * scale );            canvas.drawCircle( cx, cy, 10, paint );        }    }}</pre><p>После вызова этого метода вы должны увидеть маленькие зеленые круги, покрывающие обнаруженные грани, как показано в примере ниже.</p><figure><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=600/uploads/users/798/posts/25212/image/landmarks.png" alt="Введение в обнаружение лиц на Android..." title="Введение в обнаружение лиц на Android..." width="50" height="50"></figure><h2> <span class="sectionnum">4.</span> Дополнительные данные лица</h2><p>Хотя положение лица и его ориентиров полезно, вы также можете узнать больше информации о каждом лице, обнаруженном в вашем приложении, с помощью некоторых встроенных методов из объекта <code class="inline">Face</code>.  Методы <code class="inline">getIsSmilingProbability ()</code>, <code class="inline">getIsLeftEyeOpenProbability ()</code> и <code class="inline">getIsRightEyeOpenProbability ()</code> пытаются определить, открыты ли глаза или если обнаруженное лицо улыбается, возвращая поплавок в диапазоне от <strong>0.0</strong> до <strong>1.0</strong>.  Чем ближе к 1.0, тем более вероятно, что человек улыбается или у него открывается левый или правый глаз.</p><p>Вы также можете найти угол лица по осям Y и Z изображения, проверив его значения Эйлера.  Значение Z Euler будет всегда сообщаться, однако вы должны использовать точный режим при обнаружении граней для получения значения X.  Вы можете увидеть пример того, как получить эти значения в следующем фрагменте кода.</p><pre class="brush: java noskimlinks noskimwords">private void logFaceData() {    float smilingProbability;    float leftEyeOpenProbability;    float rightEyeOpenProbability;    float eulerY;    float eulerZ;    for( int i = 0; i &lt; mFaces.size(); i++ ) {        Face face = mFaces.valueAt(i);        smilingProbability = face.getIsSmilingProbability();        leftEyeOpenProbability = face.getIsLeftEyeOpenProbability();        rightEyeOpenProbability = face.getIsRightEyeOpenProbability();        eulerY = face.getEulerY();        eulerZ = face.getEulerZ();        Log.e( "Tuts+ Face Detection", "Smiling: " + smilingProbability );        Log.e( "Tuts+ Face Detection", "Left eye open: " + leftEyeOpenProbability );        Log.e( "Tuts+ Face Detection", "Right eye open: " + rightEyeOpenProbability );        Log.e( "Tuts+ Face Detection", "Euler Y: " + eulerY );        Log.e( "Tuts+ Face Detection", "Euler Z: " + eulerZ );    }}</pre><h2>Заключение</h2><p>В этом уроке вы узнали об одном из основных компонентов библиотеки Play Services Vision, <strong>Face Detection</strong>.  Теперь вы знаете, как распознавать лица в неподвижном изображении, как собирать информацию и находить важные ориентиры для каждого лица.</p><p>Используя то, что вы узнали, вы сможете добавить некоторые замечательные функции в свои собственные приложения для увеличения количества неподвижных изображений, отслеживания лиц в видеопотоке или всего остального, что вы можете себе представить.</p>

</div></div>

<div class="tm-article-body__tags"><div class="tm-article-body__tags-links tm-article-body__tags-links2"><span class="tm-article-body__tags-title">Теги:</span><span class="tm-article-body__tags-item"><a aria-label="Code" href="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android" class="tm-article-body__tags-item-link">Code</a></span><span class="tm-article-body__tags-item"><a aria-label="Android SDK" href="https://norma-studio.github.io/article5/220825313-vvedenie-v-obnaruzhenie-lits-na-android" class="tm-article-body__tags-item-link">Android SDK</a></span></div></div></div></article>

<div class="tm-article__icons-wrapper"><div class="tm-data-icons tm-page-article__counters-panel"><div class="tm-article-rating tm-data-icons__item"><div class="v-portal" style="display:none;"></div></div><span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title><svg id="counter-views" viewBox="0 0 56 32"><path d="M28 0c18.368 0 28 13.81 28 16s-9.632 16-28 16c-18.368 0-28-13.81-28-16s9.632-16 28-16zm0 28.309c6.874 0 12.446-5.511 12.446-12.309s-5.572-12.309-12.446-12.309-12.446 5.511-12.446 12.309 5.572 12.309 12.446 12.309zM28 16c.084-1.721 5.596-3.019 4.284-4.352-2.429-2.468-6.317-2.521-8.684-.117s-2.314 6.354.116 8.821c2.429 2.468 6.317 2.521 8.683.117 1.089-1.106-4.47-3.008-4.399-4.469z"></path></svg></svg><span class="tm-icon-counter__value">
34968</span></span><button aria-label="Добавить в закладки" title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item" onclick="return addBookmark(this);"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title><svg id="counter-favorite" viewBox="0 0 12 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 0C0.734784 0 0.48043 0.105357 0.292893 0.292893C0.105357 0.48043 0 0.734784 0 1V15C0 15.3603 0.193793 15.6927 0.507301 15.8702C0.82081 16.0477 1.20556 16.0429 1.5145 15.8575L6 13.1662L10.4855 15.8575C10.7944 16.0429 11.1792 16.0477 11.4927 15.8702C11.8062 15.6927 12 15.3603 12 15V1C12 0.447715 11.5523 0 11 0H1Z"></path></svg></svg></span><span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
514</span></button><div title="Поделиться" class="tm-sharing tm-data-icons__item">
<button aria-label="sharing" type="button" class="tm-sharing__button sharer button btn5242" data-sharer="vk" data-url="none"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button></div><div class="v-portal" style="display:none;"></div></div></div>
</div>

<div class="tm-page-article__additional-blocks wr55"></div>
<!-- pagination -->
 </div></div>
<!-- sidebar -->
<div class="tm-page__sidebar"><div id="572480" class="tm-layout-sidebar">

<div class="tm-sexy-sidebar tm-sexy-sidebar_stick-top wr54" style="margin-top: 0px;">
<section class="tm-block tm-block_spacing-bottom wr12a"></section>
<section class="tm-block tm-block_spacing-bottom wr12">

</section>
</div></div></div></div></div></div></main></div><div id="exbottom" class="tm-footer wr56"></div></div><div class="vue-portal-target"></div></div>
<link rel="stylesheet" href="../style.css">
<script src="../jquery-3.7.0.min.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y9PLTD9XQE"></script><script>window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag("js", new Date());gtag("config", "G-Y9PLTD9XQE");</script><script>(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};m[i].l=1*new Date();for (var j = 0; j < document.scripts.length; j++) {if (document.scripts[j].src === r) { return; }}k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})(window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");ym(63258550, "init", {clickmap:true,trackLinks:true,accurateTrackBounce:true});</script><noscript><div><img src="https://mc.yandex.ru/watch/63258550" style="position:absolute; left:-9999px;" alt="" /></div></noscript></body></html>
