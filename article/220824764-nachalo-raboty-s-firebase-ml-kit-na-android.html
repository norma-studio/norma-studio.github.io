
<!DOCTYPE html>
<html lang="ru"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
<title>Начало работы с Firebase ML Kit на Android... | envatomarket.ru | norma-studio.github.io</title>
<meta name="twitter:card" content="summary_large_image">
<meta property="og:title" content="Начало работы с Firebase ML Kit на Android... | envatomarket.ru | norma-studio.github.io">
<meta name="twitter:title" content="Начало работы с Firebase ML Kit на Android... | envatomarket.ru | norma-studio.github.io">
<meta name="aiturec:title" content="Начало работы с Firebase ML Kit на Android... | envatomarket.ru | norma-studio.github.io">
<meta name="description" content="Благодаря TensorFlow Mobile и TensorFlow Lite внедрение и использование глубоких моделей в приложениях для Android стало очень простым. Однако разработка и обучение моделей по-прежнему требует большого мастерства, времени и усилий, не говоря уже о вычислительной мощности. По этой причине большинство разработчиков неохотно используют возможности маш...">
<meta property="og:description" content="Благодаря TensorFlow Mobile и TensorFlow Lite внедрение и использование глубоких моделей в приложениях для Android стало очень простым. Однако разработка и обучение моделей по-прежнему требует большого мастерства, времени и усилий, не говоря уже о вычислительной мощности. По этой причине большинство разработчиков неохотно используют возможности маш...">
<meta name="twitter:description" content="Благодаря TensorFlow Mobile и TensorFlow Lite внедрение и использование глубоких моделей в приложениях для Android стало очень простым. Однако разработка и обучение моделей по-прежнему требует большого мастерства, времени и усилий, не говоря уже о вычислительной мощности. По этой причине большинство разработчиков неохотно используют возможности маш...">
<meta property="aiturec:description" content="Благодаря TensorFlow Mobile и TensorFlow Lite внедрение и использование глубоких моделей в приложениях для Android стало очень простым. Однако разработка и обучение моделей по-прежнему требует большого мастерства, времени и усилий, не говоря уже о вычислительной мощности. По этой причине большинство разработчиков неохотно используют возможности маш...">
<meta property="og:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/addnew.png">
<meta property="aiturec:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/addnew.png">
<meta name="twitter:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/addnew.png">
<meta property="vk:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/addnew.png">
<meta property="og:type" content="article">
<link image_src="image" href="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/addnew.png">
<meta property="og:locale" content="ru_RU"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name="robots" content="all">
<meta name="author" content="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android.html">
<meta name="copyright" lang="ru" content="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android.html">
<link rel="canonical" href="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android.html">
<meta property="og:url" content="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android.html">
<meta name="twitter:site" content="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android.html">
<meta name="twitter:creator" content="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android.html">

<meta name="apple-mobile-web-app-status-bar-style" content="#303b44"><meta name="msapplication-TileColor" content="#629FBC">
<link rel="shortcut icon" type="image/ico" sizes="64x64" href="https://norma-studio.github.io//norma-logo-64.png">
<link rel="shortcut icon" href="https://norma-studio.github.io//favicon.ico" type="image/x-icon">
<style>body{opacity: 0;}</style>
<meta name="yandex-verification" content="da91da9b0b6d5dba"><meta name="google-site-verification" content="_BCz7bv6IKv32EI5NSdb9dPwP4PnhlsToVoSOpbZlZI"></head><body>
<div id="app"><div class="tm-layout__wrapper"><div></div>
<header id="extop" class="tm-header"><div class="tm-page-width"><div class="tm-header__container">

<span class="tm-header__logo-wrap"><a aria-label="norma-studio.github.io" href="https://norma-studio.github.io/" class="tm-header__logo tm-header__logo_ru" title="Подборка эксклюзивных материалов о создании и продвижении сайтов, дизайне сайтов и интернет-маркетинге. Как создать и продвигать сайт, как выбрать дизайн сайта и интернет-стратегию, как защитить свои права в интернете, как продать контент для сайтов? Все ответы в блоге norma-studio.github.io">norma-studio.github.io</a></span><div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title><svg id="arrow-down" viewBox="0 0 24 24"><path d="m6.47 9.47c.293-.293.768-.293 1.061 0l4.47 4.47 4.47-4.47c.293-.293.768-.293 1.061 0s.293.768 0 1.061l-5 5c-.293.293-.768.293-1.061 0l-5-5c-.293-.293-.293-.768 0-1.061z"></path></svg></svg></button></div></div><a aria-label="Написать нам" href="https://wa.me/79603570433?text=https://norma-studio.github.io/_Добрый_день" class="tm-header__become-author-btn" title="Подборка эксклюзивных материалов о создании и продвижении сайтов, дизайне сайтов и интернет-маркетинге. Как создать и продвигать сайт, как выбрать дизайн сайта и интернет-стратегию, как защитить свои права в интернете, как продать контент для сайтов? Все ответы в блоге envatomarket.ru.">Написать нам</a><div class="tm-feature tm-header__feature tm-feature_variant-inline"></div></div></div></header>

<div class="tm-layout">
<main class="tm-layout__container"><div class="tm-page"><div class="tm-page-width"><div class="tm-page__wrapper">
<div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down">
<div class="tm-page-article__body data-container" style="background-color: #f0f0f0;" id="data-container">


<article class="tm-page-article__content tm-page-article__content_inner" style="background-color: #fff;">
<!-- article-header -->
<div class="tm-page-article__head-wrapper"><div class="tm-article-snippet tm-page-article__snippet">

<div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a aria-label="author-image" href="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android.html" title="Начало работы с Firebase ML Kit на Android... | envatomarket.ru | norma-studio.github.io" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="Начало работы с Firebase ML Kit на Android... | envatomarket.ru | norma-studio.github.io" title="Начало работы с Firebase ML Kit на Android... | envatomarket.ru | norma-studio.github.io" height="24" src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-src="https://envatomarket.ru/i3/31231313312.webp" width="24" class="tm-entity-image__pic lazy07"></div></a><span class="tm-user-info__user">
<a href="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android.html" class="tm-user-info__username" title="
Д. Грунин" aria-label="
Д. Грунин">
Д. Грунин</a>
</span></span><span class="tm-article-snippet__datetime-published"><time datetime="2023-12-09T15:24:38.000Z" title="22023-12-09, 19:24"> 09.12.2023</time></span></div></div>
<h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1" itemprop="name"><span><span>Начало работы с Firebase ML Kit на Android...</span></span></h1>
<div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a aria-label="Code" href="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android" class="tm-article-snippet__hubs-item-link"><span>Code</span></a></span><span class="tm-article-snippet__hubs-item"><a aria-label="Android SDK" href="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android" class="tm-article-snippet__hubs-item-link"><span>Android SDK</span></a></span><br></div></div>

<div itemscope itemtype="https://schema.org/Article" style="display:none;">
    <link itemprop="mainEntityOfPage" href="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android.html" />
    <link itemprop="image" href="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/addnew.png">
    <meta itemprop="headline name" content="Начало работы с Firebase ML Kit на Android... | envatomarket.ru | norma-studio.github.io">
    <meta itemprop="description" content="Благодаря TensorFlow Mobile и TensorFlow Lite внедрение и использование глубоких моделей в приложениях для Android стало очень простым. Однако разработка и обучение моделей по-прежнему требует большого мастерства, времени и усилий, не говоря уже о вычислительной мощности. По этой причине большинство разработчиков неохотно используют возможности маш...">
    <meta itemprop="author" content="norma-studio.github.io">
    <meta itemprop="datePublished" datetime="2023-12-09T15:24:38.000Z" content="09.12.2023">
    <meta itemprop="dateModified" datetime="2023-12-09T15:24:38.000Z" content="09.12.2023">
    <div itemprop="publisher" itemscope itemtype="https://schema.org/Organization">
        <div itemprop="logo" itemscope itemtype="https://schema.org/ImageObject">
            <img class="lazy07" itemprop="url image" src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-src="https://envatomarket.ru/apple-touch-icon-120.ico" alt="Шаблоны сайтов | Лендинги" title="Шаблоны сайтов | Лендинги" style="display:none;"/>
        </div>
        <meta itemprop="name" content="https://norma-studio.github.io/">
        <meta itemprop="telephone" content="">
        <meta itemprop="address" content="Россия">
    </div>
    <p>Интро</p>
    <span itemprop="articleBody">Благодаря TensorFlow Mobile и TensorFlow Lite внедрение и использование глубоких моделей в приложениях для Android стало очень простым. Однако разработка и обучение моделей по-прежнему требует большого мастерства, времени и усилий, не говоря уже о вычислительной мощности. По этой причине большинство разработчиков неохотно используют возможности маш...</span>
</div>


<!-- article-body -->

<div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-2">



<p>Благодаря TensorFlow Mobile и TensorFlow Lite внедрение и использование глубоких моделей в приложениях для Android стало очень простым. Однако разработка и обучение моделей по-прежнему требует большого мастерства, времени и усилий, не говоря уже о вычислительной мощности. По этой причине большинство разработчиков неохотно используют возможности машинного обучения для своих приложений. С F<span>irebase ML Kit</span> Google надеется изменить это.</p><p>Firebase ML Kit - это библиотека, которая позволяет вам легко и с минимальным кодом использовать множество высокоточных, предварительно обученных глубоких моделей в ваших приложениях для Android. Большинство предлагаемых моделей доступны как локально, так и в Google Cloud.<br></p><p>В настоящее время модели ограничены только задачами, связанными с компьютерным видением, такими как оптическое распознавание символов, сканирование штрих-кодов и обнаружение объектов.<br></p><p>В этом уроке я расскажу вам, как добавить Firebase ML Kit в проект Android Studio и использовать некоторые из его базовых API.<br></p><h2>Предпосылки</h2><p>Прежде чем продолжить, убедитесь, что у вас есть доступ к следующему:<br></p><ul><li>последняя версия <span>Android Studio</span> </li> <li>устройство или эмулятор под управлением Android API уровня 21 или выше</li> <li>аккаунт в <span>Firebase</span></li> <li><span>Google Cloud</span>-аккаунт</li> </ul><h2> <span class="sectionnum">1.</span> Создаём проект Firebase</h2><p>Чтобы подключить службы Firebase для вашего приложения, вы должны создать для него проект Firebase. Войдите в <span>консоль Firebase</span> и на экране приветствия нажмите кнопку «<strong>Добавить проект</strong>».<br></p><p><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/addnew.png" alt="Начало работы с Firebase ML Kit на Android..." title="Начало работы с Firebase ML Kit на Android..." width="50" height="50"><br></p><p>В появившемся диалоговом окне дайте проекту имя, которое легко запомнить, и нажмите кнопку «<strong>Создать проект</strong>».<br></p><p><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/form1.png" alt="Начало работы с Firebase ML Kit на Android..." title="Начало работы с Firebase ML Kit на Android..." width="50" height="50"><br></p><p>Через несколько секунд вы увидите уведомление о том, что новый проект готов. Нажмите кнопку «<strong>Продолжить</strong>», чтобы продолжить.<br></p><p>На следующем экране перейдите в раздел «<strong>Разработка</strong>» и нажмите ссылку «<strong>ML Kit</strong>», чтобы увидеть все предложения ML Kit.</p><figure><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/services.png" alt="Начало работы с Firebase ML Kit на Android..." title="Начало работы с Firebase ML Kit на Android..." width="50" height="50"></figure><p>В этом уроке мы будем использовать три службы: распознавание текста, распознавание лиц и маркировку изображений. Вам не нужно предпринимать какие-либо шаги, чтобы явно подключить их, если вы намереваетесь работать только с локальными моделями, поставляемыми с ML Kit. Однако в этом учебнике мы будем использовать как локальные, так и облачные модели. Поэтому нажмите ссылку <strong>«Использование облачного API</strong>».<br></p><p>Теперь вы попадете на консоль Google Cloud, где вы можете просто нажать кнопку <strong>Enable</strong>, показанную в разделе Cloud Vision API, чтобы активировать облачные модели. Обратите внимание, однако, что это будет работать только в том случае, если для вашей учетной записи Google Cloud включены платежи.</p><figure><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/clvision.png" alt="Начало работы с Firebase ML Kit на Android..." title="Начало работы с Firebase ML Kit на Android..." width="50" height="50"></figure><h2> <span class="sectionnum">2.</span> Настройка проекта Android Studio</h2><p>Прежде чем вы начнете использовать API Firebase ML Kit, вы должны установить соединение между вашим проектом Android Studio и проектом Firebase, созданным на предыдущем шаге. Для этого откройте панель Firebase Assistant, перейдя в меню <strong>Инструменты&gt; Firebase</strong>.<br></p><p>У Firebase Assistant в настоящее время нет поддержки ML Kit. Тем не менее, используя его для добавления Firebase Analytics, вы все равно можете не устанавливать соединение вручную. Поэтому разверните раздел <strong>Аналитика</strong>, нажмите ссылку <strong>Добавить событие Analytics</strong> и нажмите кнопку <strong>Подключиться к Firebase</strong>.<br></p><p>В появившемся диалоговом окне убедитесь, что вы выбрали опцию <strong>Выбрать существующий Firebase или Google проект</strong> и выберите проект, который вы создали.</p><figure><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/connect.png" alt="Начало работы с Firebase ML Kit на Android..." title="Начало работы с Firebase ML Kit на Android..." width="50" height="50"></figure><p>Нажмите кнопку <strong>Подключиться к Firebase</strong>. На этом этапе помощник автоматически загрузит файл <strong>google-services.json</strong>, содержащий ключи API и идентификаторы проектов, и добавит его в модуль <code class="inline">app</code>.<br></p><p>После того, как соединение будет успешно установлено, убедитесь, что вы нажали кнопку <strong>Добавить Google Analytics в ваше приложение</strong>, чтобы добавить различные базовые зависимости Firebase к файлу <strong>build.gradle</strong> вашего модуля <code class="inline">app</code>.<br></p><p>Затем, чтобы добавить библиотеку ML Kit, откройте файл <strong>build.gradle</strong> и введите следующие реализации <code class="inline">implementation</code>:</p><pre class="brush: groovy noskimlinks noskimwords">implementation "com.google.firebase:firebase-ml-vision:16.0.0"implementation "com.google.firebase:firebase-ml-vision-image-label-model:15.0.0"</pre><p>Чтобы упростить процесс загрузки изображений из Интернета и отображения их в приложении, я предлагаю вам также добавить зависимость для библиотеки <span>Picasso</span>.</p><pre class="brush: groovy noskimlinks noskimwords">implementation "com.squareup.picasso:picasso:2.5.2"</pre><p>Кроме того, добавьте <span>Anko</span> в качестве зависимости, чтобы убедиться, что код Kotlin является кратким и интуитивным.</p><pre class="brush: groovy noskimlinks noskimwords">implementation "org.jetbrains.anko:anko-commons:0.10.5"</pre><p>По умолчанию локальные модели Firebase ML Kit автоматически загружаются на устройства пользователя только по мере необходимости. Однако, если вы хотите, чтобы они были загружены сразу после установки вашего приложения, добавьте следующий код в файл <strong>AndroidManifest.xml</strong>:</p><pre class="brush: xml noskimlinks noskimwords">&lt;meta-data    android:name="com.google.firebase.ml.vision.DEPENDENCIES"    android:value="text,face,label" /&gt;</pre><h2> <span class="sectionnum">3.</span> Определите макет</h2><p>В этой статье мы создадим приложение, которое позволяет пользователям вводить URL-адреса изображений и выполнять на них распознавание текста, распознавания лиц и лейблинг изображений. Поэтому в макете приложения должен быть виджет <code class="inline">EditText</code>, в котором пользователи могут вводить URL-адреса и три виджета <code class="inline">Button</code>, которые позволяют им выбирать, какую операцию они хотят выполнять. <br></p><p>При желании вы можете включить виджет <code class="inline">ImageView</code> для отображения изображений.<br></p><p>Если вы разместите все вышеперечисленные виджеты с помощью виджета <code class="inline">RelativeLayout</code>, XML-файл макета должен выглядеть так:</p><pre class="brush: xml noskimlinks noskimwords">&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;RelativeLayout    xmlns:android="http://schemas.android.com/apk/res/android"    android:layout_width="match_parent"    android:layout_height="match_parent"&gt;    &lt;EditText        android:layout_width="match_parent"        android:layout_height="wrap_content"        android:hint="Image URL"        android:id="@+id/image_url_field"        android:imeOptions="actionDone"        android:inputType="textUri"/&gt;    &lt;ImageView        android:layout_width="match_parent"        android:layout_height="300dp"        android:id="@+id/image_holder"        android:layout_below="@+id/image_url_field"        android:layout_marginTop="10dp"        android:scaleType="centerInside"/&gt;    &lt;LinearLayout        android:layout_width="match_parent"        android:layout_height="wrap_content"        android:orientation="horizontal"        android:layout_alignParentBottom="true"&gt;        &lt;Button            android:layout_width="0dp"            android:layout_height="wrap_content"            android:layout_weight="0.33"            android:text="Text"            android:onClick="recognizeText"/&gt;        &lt;Button            android:layout_width="0dp"            android:layout_height="wrap_content"            android:layout_weight="0.33"            android:text="Faces"            android:onClick="detectFaces"/&gt;        &lt;Button            android:layout_width="0dp"            android:layout_height="wrap_content"            android:layout_weight="0.33"            android:text="Labels"            android:onClick="generateLabels"/&gt;    &lt;/LinearLayout&gt;&lt;/RelativeLayout&gt;</pre><p>Вот более наглядное представление макета:</p><figure><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/layout.png" alt="Начало работы с Firebase ML Kit на Android..." title="Начало работы с Firebase ML Kit на Android..." width="50" height="50"></figure><p>В приведенном выше XML вы могли заметить, что каждая кнопка имеет атрибут <code class="inline">onClick</code>, указывающий на метод обработчика событий на клике. Эти методы еще не существуют, поэтому создайте их внутри своей деятельности.</p><pre class="brush: actionscript3 noskimlinks noskimwords">fun recognizeText(v: View) {    // To do   }fun detectFaces(v: View) {    // To do}fun generateLabels(v: View) {    // To do}</pre><h2> <span class="sectionnum">4.</span> Загрузка изображения</h2><p>Когда пользователь нажимает клавишу <strong>Готово</strong> после ввода URL-адреса изображения в виджет <code class="inline">EditText</code>, наше приложение должно загрузить изображение и отобразить его внутри виджета <code class="inline">ImageView</code>.</p><p>Чтобы обнаружить действия, выполняемые на виртуальной клавиатуре пользователя, сопоставьте объект <code class="inline">OnEditorActionListener</code> с виджемом <code class="inline">EditText</code>. Внутри слушателя, после подтверждения того, что было выполнено действие <code class="inline">IME_ACTION_DONE</code>, вы можете просто вызвать методы Picasso <code class="inline">load()</code> и <code class="inline">into()</code> для загрузки и отображения изображения соответственно.<br></p><p>Соответственно, добавьте следующий код внутри метода <code class="inline">onCreate()</code> вашей деятельности:</p><pre class="brush: actionscript3 noskimlinks noskimwords">image_url_field.setOnEditorActionListener { _, action, _ -&gt;    if (action == EditorInfo.IME_ACTION_DONE) {        Picasso.with(ctx).load(image_url_field.text.toString())                .into(image_holder)        true    }    false}</pre><h2> <span class="sectionnum">5.</span> Распознование текста</h2><p>Firebase ML Kit имеет отдельные классы детекторов для всех различных операций распознавания изображений, которые он предлагает. Чтобы распознать текст, вы должны либо использовать класс <code class="inline">FirebaseVisionTextDetector</code>, который зависит от локальной модели, либо использовать класс <code class="inline">FirebaseVisionCloudTextDetector</code>, который зависит от облачной модели. Пока что, давайте использовать первый. Он намного быстрее, но он может обрабатывать текст, написанный только на латинском алфавите.<br></p><p>Детектор ML Kit ожидает, что его вход будет в виде объекта <code class="inline">FirebaseVisionImage</code>. Чтобы создать такой объект, все, что вам нужно сделать, это вызвать метод <code class="inline">fromBitmap()</code> класса <code class="inline">FirebaseVisionImage</code> и передать ему растровое изображение. Следующий код, который должен быть добавлен в обработчик события <code class="inline">recognizeText()</code>, который мы создали ранее, показывает, как преобразовать изображение, которое отображается в виджетах <code class="inline">ImageView</code>, в растровое изображение, а затем создать из него объект <code class="inline">FirebaseVisionImage</code>:</p><pre class="brush: actionscript3 noskimlinks noskimwords">val textImage = FirebaseVisionImage.fromBitmap(        (image_holder.drawable as BitmapDrawable).bitmap)</pre><p>Затем, чтобы получить ссылку на объект <code class="inline">FirebaseVisionTextDetector</code>, вы должны использовать экземпляр <code class="inline">FirebaseVision</code>.</p><pre class="brush: actionscript3 noskimlinks noskimwords">val detector = FirebaseVision.getInstance().visionTextDetector</pre><p>Теперь вы можете начать процесс распознавания текста, вызвав метод <code class="inline">detectInImage()</code> и передав ему объект <code class="inline">FirebaseVisionImage</code>. Поскольку метод выполняется асинхронно, он возвращает объект <code class="inline">Task</code>. Следовательно, чтобы иметь возможность обрабатывать результат, когда он доступен, вы должны приложить к нему экземпляр <code class="inline">OnCompleteListener</code>. Вот как:</p><pre class="brush: actionscript3 noskimlinks noskimwords">detector.detectInImage(textImage)        .addOnCompleteListener {            // More code here        }</pre><p>Внутри слушателя вы получите доступ к списку объектов <code class="inline">Block</code>. В общем, каждый блок можно рассматривать как отдельный абзац, обнаруженный на изображении. Просмотрев свойства <code class="inline">text</code> всех объектов <code class="inline">Block</code>, вы можете определить весь текст, который был обнаружен. Следующий код показывает вам, как это сделать:</p><pre class="brush: actionscript3 noskimlinks noskimwords">var detectedText = ""it.result.blocks.forEach {    detectedText += it.text + "\n"}</pre><p>То, как вы используете обнаруженный текст, конечно, зависит от вас. Пока же давайте просто отобразим его с помощью диалогового окна предупреждения. Используем Anko функцию<code class="inline"> alert()</code>.</p><pre class="brush: actionscript3 noskimlinks noskimwords">runOnUiThread {    alert(detectedText, "Text").show()}</pre><p>В приведенном выше коде метод <code class="inline">runOnUiThread()</code> гарантирует, что функция <code class="inline">alert()</code> запускается в основном потоке приложения.</p><p>Наконец, как только вы закончите использовать детектор, вы должны помнить, что вызываете его метод <code class="inline">close()</code>, чтобы освободить все ресурсы, которые он хранит.</p><pre class="brush: actionscript3 noskimlinks noskimwords">detector.close()</pre><p>Если вы сейчас запустите приложение, введите URL-адрес изображения, содержащего большое количество текста, и нажмите кнопку <strong>Текст</strong>, вы сможете увидеть действие службы распознавания текста ML Kit.</p><figure><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/pho1.png" alt="Начало работы с Firebase ML Kit на Android..." title="Начало работы с Firebase ML Kit на Android..." width="50" height="50"></figure><p><span class="sectionnum">Локальная модель ML Kit для распознавания текста достаточно точна для большинства видов печатного текста.</span></p><h2> <span class="sectionnum">6. </span>Обнаружение лиц</h2><p>Несмотря на то, что у них нет общего интерфейса высокого уровня, большинство классов детектора имеют одинаковые методы. Это означает, что обнаружение лиц в изображении не слишком отличается от распознавания текста. Однако обратите внимание, что в настоящее время ML Kit предлагает только локальную модель обнаружения лиц, к которой можно получить доступ, используя класс <code class="inline">FirebaseVisionFaceDetector</code>. Вы можете получить ссылку на экземпляр, используя класс <code class="inline">FirebaseVision</code>.<br></p><p>Добавьте следующий код в метод <code class="inline">detectFaces()</code>:</p><pre class="brush: actionscript3 noskimlinks noskimwords">val detector = FirebaseVision.getInstance().visionFaceDetector</pre><p>Вызвав метод <code class="inline">detectInImage()</code> и передав ему растровое изображение, вы можете запустить процесс обнаружения лица асинхронно. Используя экземпляр <code class="inline">OnCompleteListener</code>, прикрепленный к объекту <code class="inline">Task</code>, он возвращается, вы можете легко узнать, когда процесс будет завершен.</p><pre class="brush: actionscript3 noskimlinks noskimwords">detector.detectInImage(FirebaseVisionImage.fromBitmap(            (image_holder.drawable as BitmapDrawable).bitmap        )).addOnCompleteListener {            // More code here                }</pre><p>Внутри слушателя вы получите доступ к списку объектов <code class="inline">FirebaseVisionFace</code>, которые содержат координаты прямоугольников, которые описывают обнаруженные лица. Итак, давайте теперь нарисуем эти прямоугольники над копией исходного изображения, которое было обработано.</p><p>Чтобы создать копию растрового изображения исходного изображения, вы должны использовать его метод <code class="inline">copy()</code>, как показано ниже:</p><pre class="brush: actionscript3 noskimlinks noskimwords">var markedBitmap =    (image_holder.drawable as BitmapDrawable)            .bitmap            .copy(Bitmap.Config.ARGB_8888, true)</pre><p>Затем, чтобы иметь возможность рисовать новое растровое изображение, вы должны создать для него объекты <code class="inline">Canvas</code> и <code class="inline">Paint</code>. Использование слегка прозрачного цвета для прямоугольников было бы идеальным.</p><pre class="brush: actionscript3 noskimlinks noskimwords">val canvas = Canvas(markedBitmap)val paint = Paint(Paint.ANTI_ALIAS_FLAG)paint.color = Color.parseColor("#99003399")                            // semi-transparent blue</pre><p>На этом этапе вы можете просто пропустить список объектов <code class="inline">FirebaseVisionFace</code> и использовать их свойства <code class="inline">boundingBox</code> для рисования прямоугольников над обнаруженными лицами.</p><pre class="brush: actionscript3 noskimlinks noskimwords">it.result.forEach {    canvas.drawRect(it.boundingBox, paint)}</pre><p>Наконец, не забудьте передать новое растровое изображение в виджет <code class="inline">ImageView</code>, когда оно будет готово.</p><pre class="brush: actionscript3 noskimlinks noskimwords">runOnUiThread {    image_holder.setImageBitmap(markedBitmap)}</pre><p>Если вы сейчас запустите приложение, вы сможете выполнять обнаружение лица на любом изображении, в котором есть люди.</p><figure><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/pho2.png" alt="Начало работы с Firebase ML Kit на Android..." title="Начало работы с Firebase ML Kit на Android..." width="50" height="50"></figure><p>Я уверен, что вы будете впечатлены тем, насколько быстрыми и точными являются операции обнаружения лица ML Kit.</p><h2> <span class="sectionnum">7.</span> Создание меток</h2><p>Чтобы создавать метки для изображения, вы должны использовать либо класс <code class="inline">FirebaseVisionLabelDetector</code> на основе модели, либо класс <code class="inline">FirebaseVisionCloudLabelDetector</code> на основе облачных моделей. Поскольку в этом руководстве мы использовали только локальные модели, давайте теперь используем облачную модель. Чтобы получить ссылку на экземпляр класса <code class="inline">FirebaseVisionCloudLabelDetector</code>, вы должны снова использовать класс <code class="inline">FirebaseVision</code>.<br></p><p>Добавьте следующий код в метод <code class="inline">generateLabels()</code>:</p><pre class="brush: actionscript3 noskimlinks noskimwords">val detector =         FirebaseVision.getInstance().visionCloudLabelDetector</pre><p>Затем, как обычно, вызовите метод <code class="inline">detectInImage()</code> и присвойте экземпляру <code class="inline">OnCompleteListener</code> его возвращаемое значение.</p><pre class="brush: actionscript3 noskimlinks noskimwords">detector.detectInImage(FirebaseVisionImage.fromBitmap(            (image_holder.drawable as BitmapDrawable).bitmap        )).addOnCompleteListener {            // More code here        }</pre><p>На этот раз внутри слушателя вы получите доступ к списку объектов <code class="inline">FirebaseVisionCloudLabel</code>, каждый из которых имеет свойство <code class="inline">label</code>, содержащее потенциальную метку для изображения. Каждая метка также имеет свойство <code class="inline">confidence</code>, связанное с ней, с указанием того, насколько уверен ML Kit в отношении метки.</p><p>Следующий код показывает вам, как перебирать список меток и генерировать диалоговое окно с предупреждением, отображающее только те метки, чьи показатели доверия составляют более 70%.</p><pre class="brush: actionscript3 noskimlinks noskimwords">var output = ""it.result.forEach {    if(it.confidence &gt; 0.7)        output += it.label + "\n"}runOnUiThread {    alert(output, "Labels").show()}</pre><p>Продолжайте и снова запустите приложение, чтобы узнать, какие ярлыки создаются вашим приложением для изображений, которые вы ему предоставляете.</p><figure><img src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" class="lazy07" data-src="https://cms-assets.tutsplus.com/cdn-cgi/image/width=850/uploads/users/362/posts/31305/image/pho3.png" alt="Начало работы с Firebase ML Kit на Android..." title="Начало работы с Firebase ML Kit на Android..." width="50" height="50"></figure><h2>Заключение<br></h2><p>С Firebase ML Kit Google хочет сделать машинное обучение таким же доступным, как и более простые задачи, такие как аналитика и отчеты о сбоях. В этой вводной статье вы узнали, как работать с некоторыми из базовых API в приложениях для Android. Вы также узнали, как использовать как облачные, так и локальные модели, которые он предлагает.<br></p><p>Чтобы узнать больше, обратитесь к официальной <span>документации</span>.</p>

</div></div>

<div class="tm-article-body__tags"><div class="tm-article-body__tags-links tm-article-body__tags-links2"><span class="tm-article-body__tags-title">Теги:</span><span class="tm-article-body__tags-item"><a aria-label="Code" href="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android" class="tm-article-body__tags-item-link">Code</a></span><span class="tm-article-body__tags-item"><a aria-label="Android SDK" href="https://norma-studio.github.io/article/220824764-nachalo-raboty-s-firebase-ml-kit-na-android" class="tm-article-body__tags-item-link">Android SDK</a></span></div></div></div></article>

<div class="tm-article__icons-wrapper"><div class="tm-data-icons tm-page-article__counters-panel"><div class="tm-article-rating tm-data-icons__item"><div class="v-portal" style="display:none;"></div></div><span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title><svg id="counter-views" viewBox="0 0 56 32"><path d="M28 0c18.368 0 28 13.81 28 16s-9.632 16-28 16c-18.368 0-28-13.81-28-16s9.632-16 28-16zm0 28.309c6.874 0 12.446-5.511 12.446-12.309s-5.572-12.309-12.446-12.309-12.446 5.511-12.446 12.309 5.572 12.309 12.446 12.309zM28 16c.084-1.721 5.596-3.019 4.284-4.352-2.429-2.468-6.317-2.521-8.684-.117s-2.314 6.354.116 8.821c2.429 2.468 6.317 2.521 8.683.117 1.089-1.106-4.47-3.008-4.399-4.469z"></path></svg></svg><span class="tm-icon-counter__value">
39306</span></span><button aria-label="Добавить в закладки" title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item" onclick="return addBookmark(this);"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title><svg id="counter-favorite" viewBox="0 0 12 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 0C0.734784 0 0.48043 0.105357 0.292893 0.292893C0.105357 0.48043 0 0.734784 0 1V15C0 15.3603 0.193793 15.6927 0.507301 15.8702C0.82081 16.0477 1.20556 16.0429 1.5145 15.8575L6 13.1662L10.4855 15.8575C10.7944 16.0429 11.1792 16.0477 11.4927 15.8702C11.8062 15.6927 12 15.3603 12 15V1C12 0.447715 11.5523 0 11 0H1Z"></path></svg></svg></span><span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
442</span></button><div title="Поделиться" class="tm-sharing tm-data-icons__item">
<button aria-label="sharing" type="button" class="tm-sharing__button sharer button btn5242" data-sharer="vk" data-url="none"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button></div><div class="v-portal" style="display:none;"></div></div></div>
</div>

<div class="tm-page-article__additional-blocks wr55"></div>
<!-- pagination -->
 </div></div>
<!-- sidebar -->
<div class="tm-page__sidebar"><div id="572480" class="tm-layout-sidebar">

<div class="tm-sexy-sidebar tm-sexy-sidebar_stick-top wr54" style="margin-top: 0px;">
<section class="tm-block tm-block_spacing-bottom wr12a"></section>
<section class="tm-block tm-block_spacing-bottom wr12">

</section>
</div></div></div></div></div></div></main></div><div id="exbottom" class="tm-footer wr56"></div></div><div class="vue-portal-target"></div></div>
<link rel="stylesheet" href="../style.css">
<script src="../jquery-3.7.0.min.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y9PLTD9XQE"></script><script>window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag("js", new Date());gtag("config", "G-Y9PLTD9XQE");</script><script>(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};m[i].l=1*new Date();for (var j = 0; j < document.scripts.length; j++) {if (document.scripts[j].src === r) { return; }}k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})(window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");ym(63258550, "init", {clickmap:true,trackLinks:true,accurateTrackBounce:true});</script><noscript><div><img src="https://mc.yandex.ru/watch/63258550" style="position:absolute; left:-9999px;" alt="" /></div></noscript></body></html>
