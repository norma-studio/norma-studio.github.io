
<!DOCTYPE html>
<html lang="ru"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
<title>Скрапинг веб-страниц в Python с Beautiful Soup: основы... | envatomarket.ru | norma-studio.github.io</title>
<meta name="twitter:card" content="summary_large_image">
<meta property="og:title" content="Скрапинг веб-страниц в Python с Beautiful Soup: основы... | envatomarket.ru | norma-studio.github.io">
<meta name="twitter:title" content="Скрапинг веб-страниц в Python с Beautiful Soup: основы... | envatomarket.ru | norma-studio.github.io">
<meta name="aiturec:title" content="Скрапинг веб-страниц в Python с Beautiful Soup: основы... | envatomarket.ru | norma-studio.github.io">
<meta name="description" content="В предыдущем уроке я показал вам, как использовать модуль Requests для доступа к веб-страницам с использованием Python. В этом учебном пособии рассмотрено множество тем, таких как получение запросов GET / POST и программная загрузка таких файлов, как изображения или PDF. Единственное, чего не было в этом учебнике - руководства по скрапингу веб-стра...">
<meta property="og:description" content="В предыдущем уроке я показал вам, как использовать модуль Requests для доступа к веб-страницам с использованием Python. В этом учебном пособии рассмотрено множество тем, таких как получение запросов GET / POST и программная загрузка таких файлов, как изображения или PDF. Единственное, чего не было в этом учебнике - руководства по скрапингу веб-стра...">
<meta name="twitter:description" content="В предыдущем уроке я показал вам, как использовать модуль Requests для доступа к веб-страницам с использованием Python. В этом учебном пособии рассмотрено множество тем, таких как получение запросов GET / POST и программная загрузка таких файлов, как изображения или PDF. Единственное, чего не было в этом учебнике - руководства по скрапингу веб-стра...">
<meta property="aiturec:description" content="В предыдущем уроке я показал вам, как использовать модуль Requests для доступа к веб-страницам с использованием Python. В этом учебном пособии рассмотрено множество тем, таких как получение запросов GET / POST и программная загрузка таких файлов, как изображения или PDF. Единственное, чего не было в этом учебнике - руководства по скрапингу веб-стра...">
<meta property="og:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=80/uploads/users/1251/profiles/19759/profileImage/monty-shokeen-tutsplus.jpg">
<meta property="aiturec:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=80/uploads/users/1251/profiles/19759/profileImage/monty-shokeen-tutsplus.jpg">
<meta name="twitter:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=80/uploads/users/1251/profiles/19759/profileImage/monty-shokeen-tutsplus.jpg">
<meta property="vk:image" content="https://cms-assets.tutsplus.com/cdn-cgi/image/width=80/uploads/users/1251/profiles/19759/profileImage/monty-shokeen-tutsplus.jpg">
<meta property="og:type" content="article">
<link image_src="image" href="https://cms-assets.tutsplus.com/cdn-cgi/image/width=80/uploads/users/1251/profiles/19759/profileImage/monty-shokeen-tutsplus.jpg">
<meta property="og:locale" content="ru_RU"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name="robots" content="all">
<meta name="author" content="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy.html">
<meta name="copyright" lang="ru" content="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy.html">
<link rel="canonical" href="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy.html">
<meta property="og:url" content="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy.html">
<meta name="twitter:site" content="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy.html">
<meta name="twitter:creator" content="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy.html">

<meta name="apple-mobile-web-app-status-bar-style" content="#303b44"><meta name="msapplication-TileColor" content="#629FBC">
<link rel="shortcut icon" type="image/ico" sizes="64x64" href="https://norma-studio.github.io//norma-logo-64.png">
<link rel="shortcut icon" href="https://norma-studio.github.io//favicon.ico" type="image/x-icon">
<style>body{opacity: 0;}</style>
<meta name="yandex-verification" content="da91da9b0b6d5dba"><meta name="google-site-verification" content="_BCz7bv6IKv32EI5NSdb9dPwP4PnhlsToVoSOpbZlZI"></head><body>
<div id="app"><div class="tm-layout__wrapper"><div></div>
<header id="extop" class="tm-header"><div class="tm-page-width"><div class="tm-header__container">

<span class="tm-header__logo-wrap"><a aria-label="norma-studio.github.io" href="https://norma-studio.github.io/" class="tm-header__logo tm-header__logo_ru" title="Подборка эксклюзивных материалов о создании и продвижении сайтов, дизайне сайтов и интернет-маркетинге. Как создать и продвигать сайт, как выбрать дизайн сайта и интернет-стратегию, как защитить свои права в интернете, как продать контент для сайтов? Все ответы в блоге norma-studio.github.io">norma-studio.github.io</a></span><div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title><svg id="arrow-down" viewBox="0 0 24 24"><path d="m6.47 9.47c.293-.293.768-.293 1.061 0l4.47 4.47 4.47-4.47c.293-.293.768-.293 1.061 0s.293.768 0 1.061l-5 5c-.293.293-.768.293-1.061 0l-5-5c-.293-.293-.293-.768 0-1.061z"></path></svg></svg></button></div></div><a aria-label="Написать нам" href="https://wa.me/79603570433?text=https://norma-studio.github.io/_Добрый_день" class="tm-header__become-author-btn" title="Подборка эксклюзивных материалов о создании и продвижении сайтов, дизайне сайтов и интернет-маркетинге. Как создать и продвигать сайт, как выбрать дизайн сайта и интернет-стратегию, как защитить свои права в интернете, как продать контент для сайтов? Все ответы в блоге envatomarket.ru.">Написать нам</a><div class="tm-feature tm-header__feature tm-feature_variant-inline"></div></div></div></header>

<div class="tm-layout">
<main class="tm-layout__container"><div class="tm-page"><div class="tm-page-width"><div class="tm-page__wrapper">
<div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down">
<div class="tm-page-article__body data-container" style="background-color: #f0f0f0;" id="data-container">


<article class="tm-page-article__content tm-page-article__content_inner" style="background-color: #fff;">
<!-- article-header -->
<div class="tm-page-article__head-wrapper"><div class="tm-article-snippet tm-page-article__snippet">

<div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a aria-label="author-image" href="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy.html" title="Скрапинг веб-страниц в Python с Beautiful Soup: основы... | envatomarket.ru | norma-studio.github.io" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="Скрапинг веб-страниц в Python с Beautiful Soup: основы... | envatomarket.ru | norma-studio.github.io" title="Скрапинг веб-страниц в Python с Beautiful Soup: основы... | envatomarket.ru | norma-studio.github.io" height="24" src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-src="https://envatomarket.ru/i3/636536435.webp" width="24" class="tm-entity-image__pic lazy07"></div></a><span class="tm-user-info__user">
<a href="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy.html" class="tm-user-info__username" title="
С. Торгашев" aria-label="
С. Торгашев">
С. Торгашев</a>
</span></span><span class="tm-article-snippet__datetime-published"><time datetime="2023-12-09T15:24:38.000Z" title="22023-12-09, 19:24"> 09.12.2023</time></span></div></div>
<h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1" itemprop="name"><span><span>Скрапинг веб-страниц в Python с Beautiful Soup: основы...</span></span></h1>
<div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a aria-label="Code" href="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy" class="tm-article-snippet__hubs-item-link"><span>Code</span></a></span><span class="tm-article-snippet__hubs-item"><a aria-label="Python" href="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy" class="tm-article-snippet__hubs-item-link"><span>Python</span></a></span><br></div></div>

<div itemscope itemtype="https://schema.org/Article" style="display:none;">
    <link itemprop="mainEntityOfPage" href="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy.html" />
    <link itemprop="image" href="https://cms-assets.tutsplus.com/cdn-cgi/image/width=80/uploads/users/1251/profiles/19759/profileImage/monty-shokeen-tutsplus.jpg">
    <meta itemprop="headline name" content="Скрапинг веб-страниц в Python с Beautiful Soup: основы... | envatomarket.ru | norma-studio.github.io">
    <meta itemprop="description" content="В предыдущем уроке я показал вам, как использовать модуль Requests для доступа к веб-страницам с использованием Python. В этом учебном пособии рассмотрено множество тем, таких как получение запросов GET / POST и программная загрузка таких файлов, как изображения или PDF. Единственное, чего не было в этом учебнике - руководства по скрапингу веб-стра...">
    <meta itemprop="author" content="norma-studio.github.io">
    <meta itemprop="datePublished" datetime="2023-12-09T15:24:38.000Z" content="09.12.2023">
    <meta itemprop="dateModified" datetime="2023-12-09T15:24:38.000Z" content="09.12.2023">
    <div itemprop="publisher" itemscope itemtype="https://schema.org/Organization">
        <div itemprop="logo" itemscope itemtype="https://schema.org/ImageObject">
            <img class="lazy07" itemprop="url image" src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-src="https://envatomarket.ru/apple-touch-icon-120.ico" alt="Шаблоны сайтов | Лендинги" title="Шаблоны сайтов | Лендинги" style="display:none;"/>
        </div>
        <meta itemprop="name" content="https://norma-studio.github.io/">
        <meta itemprop="telephone" content="">
        <meta itemprop="address" content="Россия">
    </div>
    <p>Интро</p>
    <span itemprop="articleBody">В предыдущем уроке я показал вам, как использовать модуль Requests для доступа к веб-страницам с использованием Python. В этом учебном пособии рассмотрено множество тем, таких как получение запросов GET / POST и программная загрузка таких файлов, как изображения или PDF. Единственное, чего не было в этом учебнике - руководства по скрапингу веб-стра...</span>
</div>


<!-- article-body -->

<div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-2">



<p>В предыдущем уроке я показал вам, как использовать <span>модуль Requests для доступа к веб-страницам с использованием Python</span>. В этом учебном пособии рассмотрено множество тем, таких как получение запросов GET / POST и программная загрузка таких файлов, как изображения или PDF. Единственное, чего не было в этом учебнике - руководства по скрапингу веб-страниц, к которым вы обращались с помощью requests, для извлечения необходимой информации.</p><p>В этом уроке вы узнаете о <span>Beautiful Soup</span>, который представляет собой библиотеку Python для извлечения данных из файлов HTML. В этом уроке основное внимание будет уделено изучению основ библиотеки, а более подробные темы будут рассмотрены в следующем учебном пособии. Обратите внимание, что в этом руководстве для всех примеров используется Beautiful Soup 4.</p><h2>Установка</h2><p>Вы можете установить Beautiful Soup 4 с помощью <code class="inline">pip</code>. Название пакета <code class="inline">beautifulsoup4</code>. Он должен работать как на Python 2, так и на Python 3.</p><pre class="brush: python noskimlinks noskimwords">$ pip install beautifulsoup4</pre><p>Если в вашей системе нет pip, вы можете напрямую загрузить исходный <span>tarball Beautiful Soup 4</span> и установить его с помощью <code>setup.py</code>.</p><pre class="brush: python noskimlinks noskimwords">$ python setup.py install</pre><p>BeautifulSoup изначально упакован как код Python 2. Когда вы устанавливаете его для использования с Python 3, он автоматически обновляется до кода Python 3. Код не будет конвертирован, если вы не установите пакет. Вот несколько распространенных ошибок, которые вы могли заметить:</p><ul><li>«Нет модуля с именем HTMLParser» <code>ImportError</code> возникает, когда вы запускаете версию кода Python 2 под Python 3.</li> <li>«Нет модуля с именем html.parser» <code>ImportError</code> возникает, когда вы запускаете версию кода Python 3 под Python 2.</li> </ul><p>Обе приведенные выше ошибки могут быть исправлены путем удаления и переустановки Beautiful Soup.<br></p><h2>Установка парсера</h2><p>Прежде чем обсуждать различия между различными парсерами, которые вы можете использовать с Beautiful Soup, давайте напишем код для создания soup.</p><pre class="brush: python noskimlinks noskimwords">from bs4 import BeautifulSoupsoup = BeautifulSoup("&lt;html&gt;&lt;p&gt;This is &lt;b&gt;invalid HTML&lt;/p&gt;&lt;/html&gt;", "html.parser")</pre><p>Объект <code>BeautifulSoup</code> может принимать два аргумента. Первым аргументом является фактическая разметка, а второй аргумент - синтаксический анализатор, который вы хотите использовать. Различные синтаксические анализаторы: <code>html.parser</code>, <span>lxml</span> и <span>html5lib</span>. Парсер <code class="inline">lxml</code> имеет две версии: парсер HTML и синтаксический анализатор XML.</p><p><code>html.parser</code> - встроенный парсер, и он не работает так хорошо в более старых версиях Python. Вы можете установить другие синтаксические анализаторы, используя следующие команды:</p><pre class="brush: python noskimlinks noskimwords">$ pip install lxml$ pip install html5lib</pre><p>Парсер <code class="inline">lxml</code> работает очень быстро и может использоваться для быстрого анализа данных HTML. С другой стороны, парсер <code class="inline">html5lib</code> работает очень медленно, но он также очень мягкий. Ниже приведен пример использования каждого из этих синтаксических анализаторов:</p><pre class="brush: python noskimlinks noskimwords">soup = BeautifulSoup("&lt;html&gt;&lt;p&gt;This is &lt;b&gt;invalid HTML&lt;/p&gt;&lt;/html&gt;", "html.parser")print(soup)# &lt;html&gt;&lt;p&gt;This is &lt;b&gt;invalid HTML&lt;/b&gt;&lt;/p&gt;&lt;/html&gt;soup = BeautifulSoup("&lt;html&gt;&lt;p&gt;This is &lt;b&gt;invalid HTML&lt;/p&gt;&lt;/html&gt;", "lxml")print(soup)# &lt;html&gt;&lt;body&gt;&lt;p&gt;This is &lt;b&gt;invalid HTML&lt;/b&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;soup = BeautifulSoup("&lt;html&gt;&lt;p&gt;This is &lt;b&gt;invalid HTML&lt;/p&gt;&lt;/html&gt;", "xml")print(soup)# &lt;?xml version="1.0" encoding="utf-8"?&gt;# &lt;html&gt;&lt;p&gt;This is &lt;b&gt;invalid HTML&lt;/b&gt;&lt;/p&gt;&lt;/html&gt;soup = BeautifulSoup("&lt;html&gt;&lt;p&gt;This is &lt;b&gt;invalid HTML&lt;/p&gt;&lt;/html&gt;", "html5lib")print(soup)# &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is &lt;b&gt;invalid HTML&lt;/b&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</pre><p>Различия, описанные в приведенном выше примере, имеют значение только при анализе невалидного HTML. Тем не менее, большая часть HTML в Интернете невалидна, и знание этих различий поможет вам отладить некоторые ошибки синтаксического анализа и решить, какой парсер вы хотите использовать в проекте. Как правило, анализатор <code>lxml</code> является очень хорошим выбором.</p><h2>Объекты в Beautiful Soup</h2><p>Beautiful Soup анализирует данный HTML-документ в дерево объектов Python. Есть четыре основных объекта Python, о которых вам нужно знать: <code>Tag</code>, <code>NavigableString</code>, <code>BeautifulSoup</code> и <code>Comment</code>.</p><p>Объект <code>Tag</code> ссылается на фактический тег XML или HTML в документе. Вы можете получить доступ к имени тега, используя <code>tag.name</code>. Вы также можете установить имя тега на что-то еще. Изменение имени будет видно в разметке, созданной Beautiful Soup.</p><p>Вы можете получить доступ к различным атрибутам, таким как класс и идентификатор тега, используя <code>tag["class"]</code> и <code>tag["id"]</code> соответственно. Вы также можете получить доступ ко всему словарю атрибутов с помощью <code>tag.attrs</code>. Вы также можете добавлять, удалять или изменять атрибуты тега. Атрибуты элемента, такие как <code>class</code>, который может принимать несколько значений, сохраняются в виде списка.</p><p>Текст в теге хранится как <code>NavigableString</code> в Beautiful Soup. Он имеет несколько полезных методов, таких как <code>replace_with("string")</code>, чтобы заменить текст в теге. Вы также можете преобразовать строку <code>NavigableString</code> в строку unicode, используя <code>unicode()</code>.</p><p>Beautiful Soup также позволяет получить доступ к комментариям на веб-странице. Эти комментарии хранятся как объект <code>Comment</code>, который также является в основном <code>NavigableString</code>.</p><p>Вы уже узнали о объекте <code>BeautifulSoup</code> в предыдущем разделе. Он используется для представления документа в целом. Поскольку он не является фактическим объектом, он не имеет никаких имен или атрибутов.</p><h2>Получение Title, Headings и Links</h2><p>Вы можете легко извлечь заголовок страницы и другие такие данные с помощью Beautiful Soup. Давайте соберем данные со <span>страницы Википедии о Python</span>. Во-первых, вам нужно будет получить разметку страницы, используя следующий код на основе учебника модуля <span>Requests для доступа к веб-страницам</span>.</p><pre class="brush: python noskimlinks noskimwords">import requestsfrom bs4 import BeautifulSoupreq = requests.get("https://en.wikipedia.org/wiki/Python_(programming_language)")soup = BeautifulSoup(req.text, "lxml")</pre><p>Теперь, когда вы создали soup, вы можете получить заголовок веб-страницы, используя следующий код:</p><pre class="brush: python noskimlinks noskimwords">soup.title# &lt;title&gt;Python (programming language) - Wikipedia&lt;/title&gt;soup.title.name# "title"soup.title.string# "Python (programming language) - Wikipedia"</pre><p>Вы также можете получить и другую информацию с веб-страницы, такую как основной заголовок или первый абзац, их классы или атрибут <code>id</code>.</p><pre class="brush: python noskimlinks noskimwords">soup.h1# &lt;h1 class="firstHeading" id="firstHeading" lang="en"&gt;Python (programming language)&lt;/h1&gt;soup.h1.string# "Python (programming language)"soup.h1["class"]# ["firstHeading"]soup.h1["id"]# "firstHeading"soup.h1.attrs# {"class": ["firstHeading"], "id": "firstHeading", "lang": "en"}soup.h1["class"] = "firstHeading, mainHeading"soup.h1.string.replace_with("Python - Programming Language")del soup.h1["lang"]del soup.h1["id"]soup.h1# &lt;h1 class="firstHeading, mainHeading"&gt;Python - Programming Language&lt;/h1&gt;</pre><p>Аналогичным образом, вы можете перебирать все ссылки или подзаголовки в документе, используя следующий код:</p><pre class="brush: python noskimlinks noskimwords">for sub_heading in soup.find_all("h2"):    print(sub_heading.text)    # all the sub-headings like Contents, History[edit]...</pre><h2>Навигация по DOM</h2><p>Вы можете перемещаться по дереву DOM с помощью регулярных имен тегов. Связывание имен тегов может помочь вам более глубоко перемещаться по дереву. Например, вы можете получить первую ссылку в первом абзаце данной страницы Википедии, используя <code class="inline">soup.p.a</code>. Все ссылки в первом абзаце можно получить, используя <code class="inline">soup.p.find_all("a")</code>.</p><p>Вы также можете получить доступ ко всем дочерним элементам тега в виде списка с помощью <code class="inline">tag.contents</code>. Чтобы получить детей по определенному индексу, вы можете использовать <code class="inline">tag.contents[index]</code>. Вы также можете перебирать дочерние теги с помощью атрибута <code class="inline">.children</code>.</p><p>Оба <code class="inline">.children</code> и <code class="inline">.contents</code> полезны только тогда, когда вы хотите получить доступ к потомкам первого или первого уровня тега. Чтобы получить всех потомков, вы можете использовать атрибут <code class="inline">.descendants</code>.</p><pre class="brush: python noskimlinks noskimwords">print(soup.p.contents)# [&lt;b&gt;Python&lt;/b&gt;, " is a widely used ",.....the full list]print(soup.p.contents[10])# &lt;a href="/wiki/Readability" title="Readability"&gt;readability&lt;/a&gt;for child in soup.p.children:    print(child.name)# b# None# a# None# a# None# ... and so on.</pre><p>Вы также можете получить доступ к родительскому элементу элемента, используя атрибут <code class="inline">.parent</code>. Аналогично, вы можете получить доступ ко всем предкам элемента, используя атрибут <code class="inline">.parents</code>. Родитель тега &lt;html&gt; верхнего уровня - это сам объект <code class="inline">BeautifulSoup</code>, а его родительский элемент - <code class="inline">None</code>.</p><pre class="brush: python noskimlinks noskimwords">print(soup.p.parent.name)# divfor parent in soup.p.parents:    print(parent.name)# div# div# div# body# html# [document]</pre><p>Вы можете получить доступ к предыдущему и следующему родственнику элемента, используя атрибуты <code class="inline">.previous_sibling</code> и <code class="inline">.next_sibling</code>. </p><p>Для двух элементов, которые являются братьями и сестрами, они должны иметь один и тот же родитель. Это означает, что у первого ребенка элемента не будет предыдущего брата. Аналогично, у последнего дочернего элемента элемента не будет следующего брата. На реальных веб-страницах предыдущий и следующий братья элемента, скорее всего, будут символом новой строки. </p><p>Вы также можете перебирать всех братьев элемента с использованием <code class="inline">.previous_siblings</code> и <code class="inline">.next_siblings</code>.</p><pre class="brush: python noskimlinks noskimwords">soup.head.next_sibling# "\n"soup.p.a.next_sibling# " for "soup.p.a.previous_sibling# " is a widely used "print(soup.p.b.previous_sibling)# None</pre><p>Вы можете перейти к элементу, который приходит сразу после текущего элемента, используя атрибут <code class="inline">.next_element</code>. Чтобы получить доступ к элементу, который приходит непосредственно перед текущим элементом, используйте атрибут <code class="inline">.previous_element</code>. </p><p>Аналогично, вы можете перебирать все элементы, которые поступают до и после текущего элемента, используя <code class="inline">.previous_elements</code> и <code class="inline">.next_elements</code> соответственно.</p><h2>Финальные мысли</h2><p>После завершения этого урока вы должны теперь хорошо понимать основные отличия между различными парсерами HTML. Теперь вы также сможете перемещаться по веб-странице и извлекать важные данные. Это может быть полезно, когда вы хотите проанализировать все заголовки или ссылки на данном веб-сайте.</p><p>В следующей части этой серии вы узнаете, как использовать библиотеку Beautiful Soup для поиска и изменения DOM.</p>

</div></div>

<div class="tm-article-body__tags"><div class="tm-article-body__tags-links tm-article-body__tags-links2"><span class="tm-article-body__tags-title">Теги:</span><span class="tm-article-body__tags-item"><a aria-label="Code" href="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy" class="tm-article-body__tags-item-link">Code</a></span><span class="tm-article-body__tags-item"><a aria-label="Python" href="https://norma-studio.github.io/article/220824624-skraping-veb-stranits-v-python-s-beautiful-soup-osnovy" class="tm-article-body__tags-item-link">Python</a></span></div></div></div></article>

<div class="tm-article__icons-wrapper"><div class="tm-data-icons tm-page-article__counters-panel"><div class="tm-article-rating tm-data-icons__item"><div class="v-portal" style="display:none;"></div></div><span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title><svg id="counter-views" viewBox="0 0 56 32"><path d="M28 0c18.368 0 28 13.81 28 16s-9.632 16-28 16c-18.368 0-28-13.81-28-16s9.632-16 28-16zm0 28.309c6.874 0 12.446-5.511 12.446-12.309s-5.572-12.309-12.446-12.309-12.446 5.511-12.446 12.309 5.572 12.309 12.446 12.309zM28 16c.084-1.721 5.596-3.019 4.284-4.352-2.429-2.468-6.317-2.521-8.684-.117s-2.314 6.354.116 8.821c2.429 2.468 6.317 2.521 8.683.117 1.089-1.106-4.47-3.008-4.399-4.469z"></path></svg></svg><span class="tm-icon-counter__value">
31979</span></span><button aria-label="Добавить в закладки" title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item" onclick="return addBookmark(this);"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title><svg id="counter-favorite" viewBox="0 0 12 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 0C0.734784 0 0.48043 0.105357 0.292893 0.292893C0.105357 0.48043 0 0.734784 0 1V15C0 15.3603 0.193793 15.6927 0.507301 15.8702C0.82081 16.0477 1.20556 16.0429 1.5145 15.8575L6 13.1662L10.4855 15.8575C10.7944 16.0429 11.1792 16.0477 11.4927 15.8702C11.8062 15.6927 12 15.3603 12 15V1C12 0.447715 11.5523 0 11 0H1Z"></path></svg></svg></span><span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
600</span></button><div title="Поделиться" class="tm-sharing tm-data-icons__item">
<button aria-label="sharing" type="button" class="tm-sharing__button sharer button btn5242" data-sharer="vk" data-url="none"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button></div><div class="v-portal" style="display:none;"></div></div></div>
</div>

<div class="tm-page-article__additional-blocks wr55"></div>
<!-- pagination -->
 </div></div>
<!-- sidebar -->
<div class="tm-page__sidebar"><div id="572480" class="tm-layout-sidebar">

<div class="tm-sexy-sidebar tm-sexy-sidebar_stick-top wr54" style="margin-top: 0px;">
<section class="tm-block tm-block_spacing-bottom wr12a"></section>
<section class="tm-block tm-block_spacing-bottom wr12">

</section>
</div></div></div></div></div></div></main></div><div id="exbottom" class="tm-footer wr56"></div></div><div class="vue-portal-target"></div></div>
<link rel="stylesheet" href="../style.css">
<script src="../jquery-3.7.0.min.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y9PLTD9XQE"></script><script>window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag("js", new Date());gtag("config", "G-Y9PLTD9XQE");</script><script>(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};m[i].l=1*new Date();for (var j = 0; j < document.scripts.length; j++) {if (document.scripts[j].src === r) { return; }}k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})(window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");ym(63258550, "init", {clickmap:true,trackLinks:true,accurateTrackBounce:true});</script><noscript><div><img src="https://mc.yandex.ru/watch/63258550" style="position:absolute; left:-9999px;" alt="" /></div></noscript></body></html>
